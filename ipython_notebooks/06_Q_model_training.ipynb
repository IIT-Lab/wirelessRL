{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Q model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the required imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from linear_aproximation import Model\n",
    "# from environment import network\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# additional import for the Neural Network\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential, load_model\n",
    "from keras import optimizers\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>s_next</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>299475</th>\n",
       "      <td>121.0</td>\n",
       "      <td>-2.915486</td>\n",
       "      <td>[2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...</td>\n",
       "      <td>[2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299476</th>\n",
       "      <td>121.0</td>\n",
       "      <td>-3.054551</td>\n",
       "      <td>[2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...</td>\n",
       "      <td>[2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299477</th>\n",
       "      <td>121.0</td>\n",
       "      <td>-2.653020</td>\n",
       "      <td>[2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...</td>\n",
       "      <td>[2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        action    reward                                             s_next  \\\n",
       "299475   121.0 -2.915486  [2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...   \n",
       "299476   121.0 -3.054551  [2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...   \n",
       "299477   121.0 -2.653020  [2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...   \n",
       "\n",
       "                                                    state  \n",
       "299475  [2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...  \n",
       "299476  [2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...  \n",
       "299477  [2733, 2733, 2733, 3200, 3200, 3200, 2500, 250...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# path = '/Users/mawongh/OneDrive/REFERENCE FILE/D/Disertation/brainstorming/'\n",
    "path = '/home/mawongh/ws/datasets/'\n",
    "dataset = pd.read_pickle(path + 'full_dataset.pickle')\n",
    "dataset.tail(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# decorrelating samples\n",
    "N = len(dataset)\n",
    "sample_indexes = np.random.choice(np.arange(N), size = N, replace=False)\n",
    "dataset_decorr = dataset.iloc[sample_indexes]\n",
    "\n",
    "S_woScale = dataset_decorr.state.tolist()\n",
    "Snext_woScale = dataset_decorr.s_next.tolist()\n",
    "a = dataset_decorr['action'].values\n",
    "r = dataset_decorr['reward'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(S_woScale)\n",
    "S = scaler.transform(S_woScale)\n",
    "Snext = scaler.transform(Snext_woScale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model 6\n",
    "from keras.models import load_model\n",
    "modelfilename = 'MDP_model6.h5'\n",
    "\n",
    "MDP_model = load_model(path + modelfilename)\n",
    "\n",
    "# Q model\n",
    "Q_model = Sequential()\n",
    "n_cols = 105\n",
    "\n",
    "Q_model.add(Dense(400, activation = 'relu', input_shape=(n_cols,)))\n",
    "Q_model.add(Dense(400, activation = 'relu'))\n",
    "Q_model.add(Dense(400, activation = 'relu'))\n",
    "Q_model.add(Dense(126, activation = 'linear'))\n",
    "Q_model.compile(optimizer=optimizers.Adam(), loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_Qmodel_1st_pass(num_epochs = 20, gamma = 0.9):\n",
    "    for epoch in np.arange(num_epochs):\n",
    "        print('Q model, first pass, epoch: {}'.format(epoch))\n",
    "        for step in np.arange(len(S)):\n",
    "            s = S[step].reshape(1,-1)\n",
    "            s_next = Snext[step].reshape(1,-1)\n",
    "            target = r[step] + gamma * np.max(MDP_model.predict_on_batch(s_next))\n",
    "            Q_temp = Q_model.predict_on_batch(s)\n",
    "            Q_temp[0,int(a[step])] = target\n",
    "            Q_model.train_on_batch(s,Q_temp)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler_mean_file = 's_model-based_mean_.csv'\n",
    "np.savetxt(path + scaler_mean_file, scaler.mean_, delimiter=',')\n",
    "\n",
    "scaler_scale_file = 's_model-based_scale_.csv'\n",
    "np.savetxt(path + scaler_scale_file, scaler.scale_, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q model, first pass, epoch: 0\n",
      "Q model, first pass, epoch: 1\n",
      "Q model, first pass, epoch: 2\n",
      "Q model, first pass, epoch: 3\n"
     ]
    }
   ],
   "source": [
    "# train the Q model with all the samples (300K)\n",
    "train_Qmodel_1st_pass()\n",
    "print('trained!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Qmodelfilename = 'Q_model6_1stpass.h5'\n",
    "Q_model.save(path + Qmodelfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_Qmodel_2nd_pass(num_epochs = 20, gamma = 0.9):\n",
    "    for epoch in np.arange(num_epochs):\n",
    "        print('Q model, second pass, epoch: {}'.format(epoch))\n",
    "        for step in np.arange(len(S)):\n",
    "            s = S[step].reshape(1,-1)\n",
    "            s_next = Snext[step].reshape(1,-1)\n",
    "            target = r[step] + gamma * np.max(Q_model.predict_on_batch(s_next))\n",
    "            Q_temp = Q_model.predict_on_batch(s)\n",
    "            Q_temp[0,int(a[step])] = target\n",
    "            Q_model.train_on_batch(s,Q_temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q model, second pass, epoch: 0\n",
      "Q model, second pass, epoch: 1\n"
     ]
    }
   ],
   "source": [
    "# train the Q model with all the samples (300K)\n",
    "train_Qmodel_2nd_pass()\n",
    "print('trained!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Qmodelfilename = 'Q_model6_2ndpass.h5'\n",
    "Q_model.save(path + Qmodelfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Qmodel_weigths_filename = 'Q_model6_2ndpass_weights.h5'\n",
    "Q_model.save_weights(path + Qmodel_weigths_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Qmodel_1 = load_model(path + Qmodelfilename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-22.02394295, -23.89875603, -23.73156548, -23.91939735,\n",
       "       -24.12434006, -23.26884651, -23.77721405, -23.2222271 ,\n",
       "       -23.34122276, -23.72259712, -24.30957985, -23.27479935,\n",
       "       -23.953619  , -23.82709694, -23.9458065 , -23.92469025,\n",
       "       -23.90373802, -23.32255363, -23.58679199, -23.90897369,\n",
       "       -23.83125877, -23.57485962, -23.85373306, -23.61318016,\n",
       "       -23.79582405, -23.38915062, -23.30856323, -23.60995102,\n",
       "       -24.16109467, -23.71725655, -23.38339615, -23.79895973,\n",
       "       -23.49809456, -23.71014214, -24.05584717, -22.95737457,\n",
       "       -23.82899284, -23.69297218, -23.33287811, -23.90036964,\n",
       "       -24.10214615, -23.28546333, -23.72054672, -23.68875504,\n",
       "       -23.20798683, -23.06004906, -23.9834919 , -23.14255714,\n",
       "       -23.49912071, -23.89904976, -24.15880775, -23.48823929,\n",
       "       -24.23230553, -23.75199699, -24.21553421, -23.88863182,\n",
       "       -24.05475998, -23.50255775, -23.85937119, -23.36322403,\n",
       "       -24.05265236, -23.92456627, -23.48961639, -23.52483177,\n",
       "       -24.32317352, -24.03438187, -23.31007004, -23.61764717,\n",
       "       -23.85230827, -23.10040474, -24.62720108, -23.76553345,\n",
       "       -23.72644615, -23.76080894, -23.78748322, -23.81289864,\n",
       "       -23.02120399, -23.72163773, -23.90982819, -23.27828407,\n",
       "       -23.60408974, -23.05896378, -24.00040054, -23.0837841 ,\n",
       "       -23.49496651, -23.93020248, -23.76818848, -23.66948891,\n",
       "       -24.06983566, -24.01753616, -24.14551163, -23.74689293,\n",
       "       -23.90917397, -23.62204361, -24.27586365, -23.42564201,\n",
       "       -23.97928429, -24.04724503, -23.52994728, -23.64538956,\n",
       "       -23.8711071 , -23.50307846, -23.71077919, -23.96265221,\n",
       "       -23.45783043, -23.64335632, -23.91071701, -23.98021889,\n",
       "       -23.9442749 , -23.526968  , -23.76104736, -23.45517731,\n",
       "       -24.46763992, -23.83712578, -23.61495781, -23.89628792,\n",
       "       -22.91469002, -24.04037666, -24.64698792, -23.06755829,\n",
       "       -23.66005898, -23.72090721, -23.32997894, -23.79974365,\n",
       "       -23.81539726, -23.63874817], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Qmodel_1.predict(S[2].reshape(1,-1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "num_of_experiments = 10\n",
    "# S = np.array([x for x in study_dataset.state])\n",
    "\n",
    "for experiments in np.arange(num_of_experiments):\n",
    "    sample_indexes = [np.random.choice(np.arange(N), size = sz, replace=False)\n",
    "                     for sz in sample_sizes]\n",
    "    # np.random.choice(np.arange(10), size =5, replace=False)\n",
    "    study_dataset = [dataset.iloc[idx] for idx in sample_indexes]\n",
    "    \n",
    "    \n",
    "    S_woScale = [study_dataset[i].state.tolist() for i in np.arange(len(study_dataset))]\n",
    "    a_r = [df[['action', 'reward']].values for df in study_dataset]\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    S = [scaler.fit_transform(S_woScale[i]) for i in np.arange(len(S_woScale))]\n",
    "\n",
    "    \n",
    "    for ds_idx in np.arange(sample_sizes_n):\n",
    "        \n",
    "        #splitting dataset into train/test\n",
    "        S_train, S_test, a_r_train, a_r_test = train_test_split(\n",
    "            S[ds_idx], a_r[ds_idx], test_size=0.15, random_state=42)\n",
    "        \n",
    "        a_train = a_r_train[:,0]\n",
    "        a_test = a_r_test[:,0]\n",
    "        \n",
    "        r_train = a_r_train[:,1]\n",
    "        r_test = a_r_test[:,1]\n",
    "        \n",
    "#         new_S_train = np.array([S_train[i] for i in np.arange(len(S_train))])\n",
    "#         S_train = new_S_train\n",
    "#         new_S_test = np.array([S_test[i] for i in np.arange(len(S_test))])\n",
    "#         S_test = new_S_test\n",
    "\n",
    "        \n",
    "        # creates the model, it has to be every time to prevent pre-trained weights\n",
    "        model6 = Sequential()\n",
    "        n_cols = 105\n",
    "\n",
    "        # model 6\n",
    "        model6.add(Dense(400, activation = 'relu', input_shape=(n_cols,)))\n",
    "        model6.add(Dense(400, activation = 'relu'))\n",
    "        model6.add(Dense(400, activation = 'relu'))\n",
    "        model6.add(Dense(126, activation = 'linear'))\n",
    "        model6.compile(optimizer=optimizers.Adam(), loss='mean_squared_error')\n",
    "        \n",
    "        print('experiment: {}, sample_size: {}'.format(experiments,len(S[ds_idx])))\n",
    "        train_model6(num_epochs = 20)\n",
    "#         print('trained!')\n",
    "        \n",
    "        y_pred = model6.predict(S_train)\n",
    "        r_hat = np.array([y_pred[i,int(a_train[i])] for i in np.arange(len(S_train))])\n",
    "        train_MSE = mean_squared_error(r_train, r_hat)\n",
    "        print('train MSE: {}'.format(train_MSE))\n",
    "        \n",
    "        y_pred = model6.predict(S_test)\n",
    "        r_hat = np.array([y_pred[i,int(a_test[i])] for i in np.arange(len(S_test))])\n",
    "        test_MSE = mean_squared_error(r_test, r_hat)\n",
    "        print('test MSE: {}'.format(test_MSE))\n",
    "        \n",
    "        algorithm = 'NN Model 6'\n",
    "        record = df.append({'algorithm': algorithm,\n",
    "                            'sample_size': len(S[ds_idx]),\n",
    "                            'mse': train_MSE,\n",
    "                            'data': 'Train'},\n",
    "                           ignore_index=True)\n",
    "        record = record.append({'algorithm': algorithm,\n",
    "                                'sample_size': len(S[ds_idx]),\n",
    "                                'mse': test_MSE,\n",
    "                                'data': 'Test'},\n",
    "                               ignore_index=True)\n",
    "        # saves the dataframe for further analysis\n",
    "        record.to_csv(path + outputfile, mode='a', header=False, index=False)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path + outputfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = pd.read_csv(path + outputfile)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "plt.figure(figsize=(3,4), dpi=150)\n",
    "sns.boxplot(x=\"data\", y=\"mse\", data=results)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-5 + 0.9*(-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state2stateid(s):\n",
    "    return ''.join(str for str in s.astype(str).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'273327332733320032003200250025002500426642664266376637663766666666666200020002000126612661266173317331733160016001600700700700276627662766113311331133250025002500401603408014032080220320601803404022026010012026080220300384442383636443844404040444240443640363844111000101101101101001'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state2stateid(dataset.state[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array([[1,2], [1], [2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.choice(20, 30, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.min([20, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "100 % 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = np.array([10, 20, 40, 50])\n",
    "s.reshape(1,-1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.get_weights()s.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('test.h5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"%03d\" % (100,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
